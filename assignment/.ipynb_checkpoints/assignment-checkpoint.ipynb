{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling and Exploratory Data Analysis\n",
        "## Do Q1 and Q2, and one other question.\n",
        "`! git clone https://www.github.com/DS3001/assignment2`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/carascott/wranglingnote"
      ],
      "metadata": {
        "id": "1c1mLr1gRT2I",
        "outputId": "861bf7a9-7320-49fd-9c99-b234515e689b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1c1mLr1gRT2I",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wranglingnote'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 59 (delta 16), reused 7 (delta 7), pack-reused 37\u001b[K\n",
            "Receiving objects: 100% (59/59), 6.25 MiB | 17.43 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "  1. Read the abstract. What is this paper about?\n",
        "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
        "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, itâ€™s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
        "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
        "  5. How is \"Tidy Data\" defined in section 2.3?\n",
        "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
        "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
        "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1\n",
        "\n",
        "\n",
        "1) The abstract informs the reader that this paper is about standardizing the way data sets are \"tidied\". Data scientists spend the majority of their time cleaning and making data sets understandable, which is why this process must be easily replicatable and understandable."
      ],
      "metadata": {
        "id": "3_C5RrvC3_ik"
      },
      "id": "3_C5RrvC3_ik"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) The tidied data standard intends to ease the job of data scientists. In order to evaluate and manipulate the data to find/show the desired output, the data must be easily-manipulatable, such as how tidied data is described in the paper. Consistency allows the collaboration of other individuals, and the replicability of one's work. If a data scientist's code fails to clean and manipulate data, then other people will not only be unable to understand the context of the work, but there is also a great chance for innacuracy when manipulating data after cleaning/tidying."
      ],
      "metadata": {
        "id": "MT66idXm5tZE"
      },
      "id": "MT66idXm5tZE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Comparing tidy datasets to families highlights the complexity, as well as the potential messiness of a dataset (messy family & messy datasets = recipe for trouble). Generally, there is a common structure among different families, and the same is true for data sets.\n",
        "The other quote describes the issue with applying the structure of a data set to general, real-life terms. If you understand the data you are using and WHY you are doing what you're doing to the data, your results will become infintely better and more reliable. Cleaning data requires an understanding of the data you are working with, what needs to be done to make the data clearer?"
      ],
      "metadata": {
        "id": "cOslA-vX4j_p"
      },
      "id": "cOslA-vX4j_p"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Wickham described values as the data itself, and these can either be numerical or categorical/strings. A variable is defined by the various columns constiuting a data set. The types of variables depend upon the data itself, but could include things such as Gender, Age, Location, etc. Lastly, he describes observations as the rows in your data set. Each row will have values (or missing values) for each variable (columns). For example, an observation could be that of a person where the variables are defined for their particular characteristics (example: Male, 20, San Diego)."
      ],
      "metadata": {
        "id": "m_6czVCW-Np2"
      },
      "id": "m_6czVCW-Np2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Tidy data is defined by the 3 paramters: variables form columns, EACH observation forms a row, and each type of observational unit forms a table."
      ],
      "metadata": {
        "id": "7SeAd7hG_e6B"
      },
      "id": "7SeAd7hG_e6B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) The five biggest problems seen with messy data sets includes: (1) The headers (names of variables) are taken in as values, not headers, (2) One column attempting to represent more than one variable (these variables should all be seperated by column correctly), (3) The rows and columns both contain variables, (4) Different types of observations are combined within one table instead of seperate tables, and (5) A single observation unit is represented in multiple tables instead of being within one.\n",
        "\n",
        "The data is Table 4 is messy because there are 3 variables: type of religion, income range, and frequency. However, the way Table 4 is arranged does not allow frequency to be easily measured. Instead of each column having a column for each seperate income bracket, there should only be 3 columns that can include an infinite number of observations (rows). There should be less columns and more rows, not the other way around.\n",
        "\n",
        "Melting is a process of fixing the issues seen in tables such as 4, so that a data set is longer than it is wide. The resulting data can be referred to as \"molten data\"."
      ],
      "metadata": {
        "id": "xzED7Q_-B_OQ"
      },
      "id": "xzED7Q_-B_OQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Table 11 has excessive amounts of rows to denote date/day. Table 12b shows that \"element\" and \"value\" have been changed to \"tmin\" or \"tmax\" and then each observation is included in a row. Date is included as its own variable that includes year, month and day in each observatioon, allowing for easier-manipulatable data."
      ],
      "metadata": {
        "id": "XGMlePjOHiD3"
      },
      "id": "XGMlePjOHiD3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "8)"
      ],
      "metadata": {
        "id": "Ipr-b0dmJA0D"
      },
      "id": "Ipr-b0dmJA0D"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "dtnS9sqpfi5J"
      },
      "id": "dtnS9sqpfi5J",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1:"
      ],
      "metadata": {
        "id": "ptdH8e5SRbCN"
      },
      "id": "ptdH8e5SRbCN"
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = pd.read_csv('/content/wranglingnote/assignment/data/airbnb_hw.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "_LdMh9qLM_th"
      },
      "id": "_LdMh9qLM_th",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bnb.shape, '\\n')\n",
        "bnb.head()\n",
        "price = bnb['Price']\n",
        "price.unique()"
      ],
      "metadata": {
        "id": "QRL3q1p8f3EE",
        "outputId": "7ad15843-f59c-4f62-b685-fdd0f7afa838",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QRL3q1p8f3EE",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30478, 13) \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['145', '37', '28', '199', '549', '149', '250', '90', '270', '290',\n",
              "       '170', '59', '49', '68', '285', '75', '100', '150', '700', '125',\n",
              "       '175', '40', '89', '95', '99', '499', '120', '79', '110', '180',\n",
              "       '143', '230', '350', '135', '85', '60', '70', '55', '44', '200',\n",
              "       '165', '115', '74', '84', '129', '50', '185', '80', '190', '140',\n",
              "       '45', '65', '225', '600', '109', '1,990', '73', '240', '72', '105',\n",
              "       '155', '160', '42', '132', '117', '295', '280', '159', '107', '69',\n",
              "       '239', '220', '399', '130', '375', '585', '275', '139', '260',\n",
              "       '35', '133', '300', '289', '179', '98', '195', '29', '27', '39',\n",
              "       '249', '192', '142', '169', '1,000', '131', '138', '113', '122',\n",
              "       '329', '101', '475', '238', '272', '308', '126', '235', '315',\n",
              "       '248', '128', '56', '207', '450', '215', '210', '385', '445',\n",
              "       '136', '247', '118', '77', '76', '92', '198', '205', '299', '222',\n",
              "       '245', '104', '153', '349', '114', '320', '292', '226', '420',\n",
              "       '500', '325', '307', '78', '265', '108', '123', '189', '32', '58',\n",
              "       '86', '219', '800', '335', '63', '229', '425', '67', '87', '1,200',\n",
              "       '158', '650', '234', '310', '695', '400', '166', '119', '62',\n",
              "       '168', '340', '479', '43', '395', '144', '52', '47', '529', '187',\n",
              "       '209', '233', '82', '269', '163', '172', '305', '156', '550',\n",
              "       '435', '137', '124', '48', '279', '330', '5,000', '134', '378',\n",
              "       '97', '277', '64', '193', '147', '186', '264', '30', '3,000',\n",
              "       '112', '94', '379', '57', '415', '236', '410', '214', '88', '66',\n",
              "       '71', '171', '157', '545', '1,500', '83', '96', '1,800', '81',\n",
              "       '188', '380', '255', '505', '54', '33', '174', '93', '740', '640',\n",
              "       '1,300', '440', '599', '357', '1,239', '495', '127', '5,999',\n",
              "       '178', '348', '152', '242', '183', '253', '750', '259', '365',\n",
              "       '273', '197', '397', '103', '389', '355', '559', '38', '203',\n",
              "       '999', '141', '162', '333', '698', '46', '360', '895', '10', '41',\n",
              "       '206', '281', '449', '388', '212', '102', '201', '2,750', '4,750',\n",
              "       '432', '675', '167', '390', '298', '339', '194', '302', '211',\n",
              "       '595', '191', '53', '361', '480', '8,000', '4,500', '459', '997',\n",
              "       '345', '216', '218', '111', '735', '276', '91', '490', '850',\n",
              "       '398', '36', '775', '267', '625', '336', '2,500', '176', '725',\n",
              "       '3,750', '469', '106', '460', '287', '575', '227', '263', '25',\n",
              "       '228', '208', '177', '880', '148', '116', '685', '470', '217',\n",
              "       '164', '61', '645', '699', '405', '252', '319', '268', '419',\n",
              "       '343', '525', '311', '840', '154', '294', '950', '409', '184',\n",
              "       '257', '204', '241', '2,000', '412', '121', '288', '196', '900',\n",
              "       '647', '524', '1,750', '309', '510', '1,495', '1,700', '799',\n",
              "       '383', '372', '492', '327', '1,999', '656', '224', '173', '875',\n",
              "       '1,170', '795', '690', '146', '465', '1,100', '151', '274', '429',\n",
              "       '825', '282', '256', '1,111', '620', '271', '161', '51', '855',\n",
              "       '579', '1,174', '430', '20', '899', '649', '485', '181', '455',\n",
              "       '4,000', '243', '342', '590', '560', '374', '437', '232', '359',\n",
              "       '985', '31', '244', '254', '723', '237', '428', '370', '34',\n",
              "       '1,400', '580', '2,520', '221', '749', '1,600', '2,695', '306',\n",
              "       '202', '680', '570', '520', '223', '2,295', '213', '1,065', '346',\n",
              "       '24', '286', '296', '266', '26', '995', '1,368', '393', '182',\n",
              "       '635', '258', '780', '589', '347', '1,250', '1,350', '446',\n",
              "       '3,200', '1,050', '1,650', '1,550', '975', '323', '6,500', '2,499',\n",
              "       '1,850', '2,250', '715', '461', '540', '356', '439', '384', '569',\n",
              "       '1,900', '22', '785', '626', '830', '318', '444', '321', '401',\n",
              "       '1,499', '888', '369', '770', '386', '366', '344', '630', '313',\n",
              "       '597', '262', '509', '10,000', '278', '312', '789', '1,195', '422',\n",
              "       '21', '765', '3,500', '945', '326', '3,100', '2,486', '3,390',\n",
              "       '1,356', '2,599', '472', '454', '328', '396', '291'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are commas in values over a thousand, but because the list is seperated by commas, I need to replace the commas inside the values with nothing, as to not make the data set confusing or hard to work with."
      ],
      "metadata": {
        "id": "7M9AcpBtlRZF"
      },
      "id": "7M9AcpBtlRZF"
    },
    {
      "cell_type": "code",
      "source": [
        "price = price.str.replace(',','') # Updating price column instead of creating a new column\n",
        "price.unique()"
      ],
      "metadata": {
        "id": "-Ixlj4DDlgao",
        "outputId": "3de83f54-eb5b-46b6-ba03-c7fdd9e7a632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-Ixlj4DDlgao",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['145', '37', '28', '199', '549', '149', '250', '90', '270', '290',\n",
              "       '170', '59', '49', '68', '285', '75', '100', '150', '700', '125',\n",
              "       '175', '40', '89', '95', '99', '499', '120', '79', '110', '180',\n",
              "       '143', '230', '350', '135', '85', '60', '70', '55', '44', '200',\n",
              "       '165', '115', '74', '84', '129', '50', '185', '80', '190', '140',\n",
              "       '45', '65', '225', '600', '109', '1990', '73', '240', '72', '105',\n",
              "       '155', '160', '42', '132', '117', '295', '280', '159', '107', '69',\n",
              "       '239', '220', '399', '130', '375', '585', '275', '139', '260',\n",
              "       '35', '133', '300', '289', '179', '98', '195', '29', '27', '39',\n",
              "       '249', '192', '142', '169', '1000', '131', '138', '113', '122',\n",
              "       '329', '101', '475', '238', '272', '308', '126', '235', '315',\n",
              "       '248', '128', '56', '207', '450', '215', '210', '385', '445',\n",
              "       '136', '247', '118', '77', '76', '92', '198', '205', '299', '222',\n",
              "       '245', '104', '153', '349', '114', '320', '292', '226', '420',\n",
              "       '500', '325', '307', '78', '265', '108', '123', '189', '32', '58',\n",
              "       '86', '219', '800', '335', '63', '229', '425', '67', '87', '1200',\n",
              "       '158', '650', '234', '310', '695', '400', '166', '119', '62',\n",
              "       '168', '340', '479', '43', '395', '144', '52', '47', '529', '187',\n",
              "       '209', '233', '82', '269', '163', '172', '305', '156', '550',\n",
              "       '435', '137', '124', '48', '279', '330', '5000', '134', '378',\n",
              "       '97', '277', '64', '193', '147', '186', '264', '30', '3000', '112',\n",
              "       '94', '379', '57', '415', '236', '410', '214', '88', '66', '71',\n",
              "       '171', '157', '545', '1500', '83', '96', '1800', '81', '188',\n",
              "       '380', '255', '505', '54', '33', '174', '93', '740', '640', '1300',\n",
              "       '440', '599', '357', '1239', '495', '127', '5999', '178', '348',\n",
              "       '152', '242', '183', '253', '750', '259', '365', '273', '197',\n",
              "       '397', '103', '389', '355', '559', '38', '203', '999', '141',\n",
              "       '162', '333', '698', '46', '360', '895', '10', '41', '206', '281',\n",
              "       '449', '388', '212', '102', '201', '2750', '4750', '432', '675',\n",
              "       '167', '390', '298', '339', '194', '302', '211', '595', '191',\n",
              "       '53', '361', '480', '8000', '4500', '459', '997', '345', '216',\n",
              "       '218', '111', '735', '276', '91', '490', '850', '398', '36', '775',\n",
              "       '267', '625', '336', '2500', '176', '725', '3750', '469', '106',\n",
              "       '460', '287', '575', '227', '263', '25', '228', '208', '177',\n",
              "       '880', '148', '116', '685', '470', '217', '164', '61', '645',\n",
              "       '699', '405', '252', '319', '268', '419', '343', '525', '311',\n",
              "       '840', '154', '294', '950', '409', '184', '257', '204', '241',\n",
              "       '2000', '412', '121', '288', '196', '900', '647', '524', '1750',\n",
              "       '309', '510', '1495', '1700', '799', '383', '372', '492', '327',\n",
              "       '1999', '656', '224', '173', '875', '1170', '795', '690', '146',\n",
              "       '465', '1100', '151', '274', '429', '825', '282', '256', '1111',\n",
              "       '620', '271', '161', '51', '855', '579', '1174', '430', '20',\n",
              "       '899', '649', '485', '181', '455', '4000', '243', '342', '590',\n",
              "       '560', '374', '437', '232', '359', '985', '31', '244', '254',\n",
              "       '723', '237', '428', '370', '34', '1400', '580', '2520', '221',\n",
              "       '749', '1600', '2695', '306', '202', '680', '570', '520', '223',\n",
              "       '2295', '213', '1065', '346', '24', '286', '296', '266', '26',\n",
              "       '995', '1368', '393', '182', '635', '258', '780', '589', '347',\n",
              "       '1250', '1350', '446', '3200', '1050', '1650', '1550', '975',\n",
              "       '323', '6500', '2499', '1850', '2250', '715', '461', '540', '356',\n",
              "       '439', '384', '569', '1900', '22', '785', '626', '830', '318',\n",
              "       '444', '321', '401', '1499', '888', '369', '770', '386', '366',\n",
              "       '344', '630', '313', '597', '262', '509', '10000', '278', '312',\n",
              "       '789', '1195', '422', '21', '765', '3500', '945', '326', '3100',\n",
              "       '2486', '3390', '1356', '2599', '472', '454', '328', '396', '291'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the thousand values, the commmas have been removed from each point of data. Success!"
      ],
      "metadata": {
        "id": "5PTqaxNimA2I"
      },
      "id": "5PTqaxNimA2I"
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(price)) # Shows that the data is still in a series, not recognized numerically"
      ],
      "metadata": {
        "id": "MZcNkSb1nhwy",
        "outputId": "5e3ac10e-1968-43fe-a31b-2361261ff383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MZcNkSb1nhwy",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price = pd.to_numeric(price, errors = 'coerce')\n",
        "print(price.unique() , '\\n')\n",
        "print(type(price))"
      ],
      "metadata": {
        "id": "MflCFo8roGeh",
        "outputId": "c414b489-7fb1-454f-a588-407d21173dbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MflCFo8roGeh",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  145    37    28   199   549   149   250    90   270   290   170    59\n",
            "    49    68   285    75   100   150   700   125   175    40    89    95\n",
            "    99   499   120    79   110   180   143   230   350   135    85    60\n",
            "    70    55    44   200   165   115    74    84   129    50   185    80\n",
            "   190   140    45    65   225   600   109  1990    73   240    72   105\n",
            "   155   160    42   132   117   295   280   159   107    69   239   220\n",
            "   399   130   375   585   275   139   260    35   133   300   289   179\n",
            "    98   195    29    27    39   249   192   142   169  1000   131   138\n",
            "   113   122   329   101   475   238   272   308   126   235   315   248\n",
            "   128    56   207   450   215   210   385   445   136   247   118    77\n",
            "    76    92   198   205   299   222   245   104   153   349   114   320\n",
            "   292   226   420   500   325   307    78   265   108   123   189    32\n",
            "    58    86   219   800   335    63   229   425    67    87  1200   158\n",
            "   650   234   310   695   400   166   119    62   168   340   479    43\n",
            "   395   144    52    47   529   187   209   233    82   269   163   172\n",
            "   305   156   550   435   137   124    48   279   330  5000   134   378\n",
            "    97   277    64   193   147   186   264    30  3000   112    94   379\n",
            "    57   415   236   410   214    88    66    71   171   157   545  1500\n",
            "    83    96  1800    81   188   380   255   505    54    33   174    93\n",
            "   740   640  1300   440   599   357  1239   495   127  5999   178   348\n",
            "   152   242   183   253   750   259   365   273   197   397   103   389\n",
            "   355   559    38   203   999   141   162   333   698    46   360   895\n",
            "    10    41   206   281   449   388   212   102   201  2750  4750   432\n",
            "   675   167   390   298   339   194   302   211   595   191    53   361\n",
            "   480  8000  4500   459   997   345   216   218   111   735   276    91\n",
            "   490   850   398    36   775   267   625   336  2500   176   725  3750\n",
            "   469   106   460   287   575   227   263    25   228   208   177   880\n",
            "   148   116   685   470   217   164    61   645   699   405   252   319\n",
            "   268   419   343   525   311   840   154   294   950   409   184   257\n",
            "   204   241  2000   412   121   288   196   900   647   524  1750   309\n",
            "   510  1495  1700   799   383   372   492   327  1999   656   224   173\n",
            "   875  1170   795   690   146   465  1100   151   274   429   825   282\n",
            "   256  1111   620   271   161    51   855   579  1174   430    20   899\n",
            "   649   485   181   455  4000   243   342   590   560   374   437   232\n",
            "   359   985    31   244   254   723   237   428   370    34  1400   580\n",
            "  2520   221   749  1600  2695   306   202   680   570   520   223  2295\n",
            "   213  1065   346    24   286   296   266    26   995  1368   393   182\n",
            "   635   258   780   589   347  1250  1350   446  3200  1050  1650  1550\n",
            "   975   323  6500  2499  1850  2250   715   461   540   356   439   384\n",
            "   569  1900    22   785   626   830   318   444   321   401  1499   888\n",
            "   369   770   386   366   344   630   313   597   262   509 10000   278\n",
            "   312   789  1195   422    21   765  3500   945   326  3100  2486  3390\n",
            "  1356  2599   472   454   328   396   291] \n",
            "\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(price.isnull())) # No missing values"
      ],
      "metadata": {
        "id": "mPt5z5vDpGTn",
        "outputId": "18540abb-3b80-41dc-902a-50d71f94c157",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mPt5z5vDpGTn",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2:"
      ],
      "metadata": {
        "id": "iSw2RFIlCwLg"
      },
      "id": "iSw2RFIlCwLg"
    },
    {
      "cell_type": "code",
      "source": [
        "shark = pd.read_csv('/content/wranglingnote/data/sharks.csv', low_memory=False)\n",
        "type = shark['Type']\n",
        "print(type.unique() , '\\n')\n",
        "shark['Type'].value_counts()"
      ],
      "metadata": {
        "id": "5u5W5fBCpno0",
        "outputId": "95b3e160-437a-4731-e3df-2c84138c01cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5u5W5fBCpno0",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unprovoked' 'Provoked' 'Questionable' 'Watercraft' 'Unconfirmed'\n",
            " 'Unverified' 'Invalid' 'Under investigation' 'Boating' 'Sea Disaster' nan\n",
            " 'Boat' 'Boatomg'] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked             4716\n",
              "Provoked                593\n",
              "Invalid                 552\n",
              "Sea Disaster            239\n",
              "Watercraft              142\n",
              "Boat                    109\n",
              "Boating                  92\n",
              "Questionable             10\n",
              "Unconfirmed               1\n",
              "Unverified                1\n",
              "Under investigation       1\n",
              "Boatomg                   1\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variables that don't make sense and should be removed: Invalid, Questionable, Unconfirmed, Unverified, Under investigation\n",
        "\n",
        "Variables that have to do with boating: Sea Disaster, Watercraft, Boat, Boating, Boatomg (is this a typo for boating?, only occurs once)"
      ],
      "metadata": {
        "id": "uqnMH175rkvg"
      },
      "id": "uqnMH175rkvg"
    },
    {
      "cell_type": "code",
      "source": [
        "type = type.replace(['Sea Disaster', 'Watercraft','Boat','Boating','Boatomg'],'All Boating')\n",
        "type.value_counts() # If these variables all mean boating, I can combine them to \"All Boating\""
      ],
      "metadata": {
        "id": "XPWiVN_7sb3_",
        "outputId": "7ac7fc4a-4dd3-4399-9665-8d7432a9b5c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XPWiVN_7sb3_",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked             4716\n",
              "Provoked                593\n",
              "All Boating             583\n",
              "Invalid                 552\n",
              "Questionable             10\n",
              "Unconfirmed               1\n",
              "Unverified                1\n",
              "Under investigation       1\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type = type.replace(['Invalid', 'Questionable','Unconfirmed','Unverified','Under investigation'],np.nan)\n",
        "type.value_counts() # Succesfully removes unnecessary data"
      ],
      "metadata": {
        "id": "B-klfiHPqCv1",
        "outputId": "5890a231-7ad4-4063-ae9d-b5837affb0fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "B-klfiHPqCv1",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked     4716\n",
              "Provoked        593\n",
              "All Boating     583\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shark['Type'].value_counts() # I created a \"type\" variable, so the changes have not been made to the actual dataset"
      ],
      "metadata": {
        "id": "LIe93HDHtvfO",
        "outputId": "8053a430-fad1-43f5-d958-ce2bd052ad09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LIe93HDHtvfO",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked             4716\n",
              "Provoked                593\n",
              "Invalid                 552\n",
              "Sea Disaster            239\n",
              "Watercraft              142\n",
              "Boat                    109\n",
              "Boating                  92\n",
              "Questionable             10\n",
              "Unconfirmed               1\n",
              "Unverified                1\n",
              "Under investigation       1\n",
              "Boatomg                   1\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shark['Type'] = type # To change the actual data set, I set these two equal to one another\n",
        "shark['Type'].value_counts()"
      ],
      "metadata": {
        "id": "Irg1GnK4uMAr",
        "outputId": "4bc392fe-5dff-4b3b-a132-1ea52a4e443e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Irg1GnK4uMAr",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked     4716\n",
              "Provoked        593\n",
              "All Boating     583\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3:"
      ],
      "metadata": {
        "id": "v9IU9fZGvZHU"
      },
      "id": "v9IU9fZGvZHU"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/October 2017 Cohort_Virginia Pretrial Data Project_Deidentified FINAL Update_10272021.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "PfeUZC7zFvPH"
      },
      "id": "PfeUZC7zFvPH",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape, '\\n')\n",
        "release = df['WhetherDefendantWasReleasedPretrial']"
      ],
      "metadata": {
        "id": "K5VbbxqXN29h",
        "outputId": "87b81f32-9341-43bd-eace-84478e52adc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "K5VbbxqXN29h",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2178, 709) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "release.unique()\n",
        "release.value_counts()"
      ],
      "metadata": {
        "id": "PPCzA5mtIoiR",
        "outputId": "46f4d212-c3b2-4ab5-9e47-1780da6ec79a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PPCzA5mtIoiR",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1186\n",
              "0     983\n",
              "9       9\n",
              "Name: WhetherDefendantWasReleasedPretrial, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "release = release.replace(9,np.nan)\n",
        "release.value_counts()"
      ],
      "metadata": {
        "id": "uHkDlddHG95V",
        "outputId": "8a340690-18ea-49cc-821b-1c96502fbf6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uHkDlddHG95V",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    1186\n",
              "0.0     983\n",
              "Name: WhetherDefendantWasReleasedPretrial, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(release.isnull()) # Gives 31 na values, 9 had 31, which was removed so this is the desired iutput!"
      ],
      "metadata": {
        "id": "86dSM7HJJwrf",
        "outputId": "93a4ae31-7138-45f4-dacb-d9e6a8921ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "86dSM7HJJwrf",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['WhetherDefendantWasReleasedPretrial'].value_counts()\n",
        "df['WhetherDefendantWasReleasedPretrial'] = release\n",
        "df['WhetherDefendantWasReleasedPretrial'].value_counts()"
      ],
      "metadata": {
        "id": "GNk9uFfrICMf",
        "outputId": "6509dd77-d338-41c2-c948-9999ba1fdd6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GNk9uFfrICMf",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    1186\n",
              "0.0     983\n",
              "Name: WhetherDefendantWasReleasedPretrial, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4:"
      ],
      "metadata": {
        "id": "Jl_H4fJaKx38"
      },
      "id": "Jl_H4fJaKx38"
    },
    {
      "cell_type": "code",
      "source": [
        "time = df['ImposedSentenceAllChargeInContactEvent']\n",
        "length = pd.to_numeric(time, errors='coerce')\n",
        "\n",
        "#print(length.head())\n",
        "#print(length.unique(), '\\n')\n",
        "#print(length.value_counts())"
      ],
      "metadata": {
        "id": "RadTTfZtK0FI"
      },
      "id": "RadTTfZtK0FI",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length_NA = length.isnull()\n",
        "print(np.sum(length_NA),'\\n')"
      ],
      "metadata": {
        "id": "PHGeUHkj3Fw6",
        "outputId": "d3d7eeb8-d85d-4a24-93b7-ac0c535c5b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PHGeUHkj3Fw6",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "652 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = length.isnull()\n",
        "missing_count = missing_values.sum()\n",
        "rows_with_missing_values = df[missing_values]\n",
        "\n",
        "#print(missing_values)\n",
        "#print(rows_with_missing_values)"
      ],
      "metadata": {
        "id": "Wo8lItwU2IF8",
        "outputId": "977dff3d-f05a-4133-80ef-e3687a43fb00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Wo8lItwU2IF8",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     InternalStudyID REQ_REC# Defendant_Sex Defendant_Race  \\\n",
            "0           ADI00001        1             M              W   \n",
            "4           CDI00038        7             F              W   \n",
            "11          CDI00050       14             M              B   \n",
            "12          CDI00055       15             F              W   \n",
            "15          CDI00089       18             F              W   \n",
            "...              ...      ...           ...            ...   \n",
            "2163        EGD00053     2168             M              W   \n",
            "2168        EGD00058     2173             M              B   \n",
            "2170        EGD00060     2175             M              B   \n",
            "2173        EGD00063     2178             F              W   \n",
            "2174        EGD00064     2179             M              B   \n",
            "\n",
            "      Defendant_BirthYear  Defendant_Age  Defendant_AgeGroup  \\\n",
            "0                    1986             31                   3   \n",
            "4                    1988             28                   3   \n",
            "11                   1992             25                   2   \n",
            "12                   1982             35                   3   \n",
            "15                   1979             38                   4   \n",
            "...                   ...            ...                 ...   \n",
            "2163                 1987             30                   3   \n",
            "2168                 1987             30                   3   \n",
            "2170                 1988             29                   3   \n",
            "2173                 1986             31                   3   \n",
            "2174                 1988             28                   3   \n",
            "\n",
            "     Defendant_AgeatCurrentArrest  Defendant_AttorneyTypeAtCaseClosure  \\\n",
            "0                              31                                   99   \n",
            "4                              28                                    0   \n",
            "11                             25                                    4   \n",
            "12                             35                                    4   \n",
            "15                             38                                    1   \n",
            "...                           ...                                  ...   \n",
            "2163                           30                                    0   \n",
            "2168                           30                                    0   \n",
            "2170                           29                                    4   \n",
            "2173                           31                                    2   \n",
            "2174                           28                                    2   \n",
            "\n",
            "      Defendant_IndigencyStatus  ... NewFelonySexualAssaultArrest_OffDate  \\\n",
            "0                            99  ...                                        \n",
            "4                             0  ...                                        \n",
            "11                            0  ...                                        \n",
            "12                            0  ...                                        \n",
            "15                            1  ...                                        \n",
            "...                         ...  ...                                  ...   \n",
            "2163                          0  ...                                        \n",
            "2168                          0  ...                                        \n",
            "2170                          0  ...                                        \n",
            "2173                          1  ...                                        \n",
            "2174                          1  ...                                        \n",
            "\n",
            "     NewFelonySexualAssaultArrest_ArrestDate  \\\n",
            "0                                              \n",
            "4                                              \n",
            "11                                             \n",
            "12                                             \n",
            "15                                             \n",
            "...                                      ...   \n",
            "2163                                           \n",
            "2168                                           \n",
            "2170                                           \n",
            "2173                                           \n",
            "2174                                           \n",
            "\n",
            "      NewFelonySexualAssaultArrest_DaysBetweenContactEventandOffDate  \\\n",
            "0                                                                      \n",
            "4                                                                      \n",
            "11                                                                     \n",
            "12                                                                     \n",
            "15                                                                     \n",
            "...                                                 ...                \n",
            "2163                                                                   \n",
            "2168                                                                   \n",
            "2170                                                                   \n",
            "2173                                                                   \n",
            "2174                                                                   \n",
            "\n",
            "     NewFelonySexualAssaultArrest_DaysBetweenOffDateandArrestDate  \\\n",
            "0                                                 999.0             \n",
            "4                                                 999.0             \n",
            "11                                                999.0             \n",
            "12                                                999.0             \n",
            "15                                                999.0             \n",
            "...                                                 ...             \n",
            "2163                                              999.0             \n",
            "2168                                              999.0             \n",
            "2170                                              999.0             \n",
            "2173                                              999.0             \n",
            "2174                                              999.0             \n",
            "\n",
            "      NewFelonySexualAssaultArrest_DaysBetweenReleaseDateandOffDate  \\\n",
            "0                                                 999.0               \n",
            "4                                                 999.0               \n",
            "11                                                999.0               \n",
            "12                                                999.0               \n",
            "15                                                999.0               \n",
            "...                                                 ...               \n",
            "2163                                              999.0               \n",
            "2168                                              999.0               \n",
            "2170                                              999.0               \n",
            "2173                                              999.0               \n",
            "2174                                              999.0               \n",
            "\n",
            "      NewFelonySexualAssaultArrest_Disposition  \\\n",
            "0                                                \n",
            "4                                                \n",
            "11                                               \n",
            "12                                               \n",
            "15                                               \n",
            "...                                        ...   \n",
            "2163                                             \n",
            "2168                                             \n",
            "2170                                             \n",
            "2173                                             \n",
            "2174                                             \n",
            "\n",
            "      Intertnalindicator_ReasonforExcludingFromFollowUpAnalysis  \\\n",
            "0                                                   4.0           \n",
            "4                                                   0.0           \n",
            "11                                                  5.0           \n",
            "12                                                  0.0           \n",
            "15                                                  0.0           \n",
            "...                                                 ...           \n",
            "2163                                                0.0           \n",
            "2168                                                1.0           \n",
            "2170                                                0.0           \n",
            "2173                                                0.0           \n",
            "2174                                                0.0           \n",
            "\n",
            "      CriminalHistoryRecordsReturnedorCMSRecordsFoundforIndividual  \\\n",
            "0                                                     1              \n",
            "4                                                     1              \n",
            "11                                                    1              \n",
            "12                                                    1              \n",
            "15                                                    1              \n",
            "...                                                 ...              \n",
            "2163                                                  1              \n",
            "2168                                                  1              \n",
            "2170                                                  1              \n",
            "2173                                                  1              \n",
            "2174                                                  1              \n",
            "\n",
            "     DispRecordFoundforChargesinOct2017Contact_Atleast1dispfound  \\\n",
            "0                                                   0.0            \n",
            "4                                                   1.0            \n",
            "11                                                  1.0            \n",
            "12                                                  1.0            \n",
            "15                                                  1.0            \n",
            "...                                                 ...            \n",
            "2163                                                1.0            \n",
            "2168                                                1.0            \n",
            "2170                                                1.0            \n",
            "2173                                                1.0            \n",
            "2174                                                1.0            \n",
            "\n",
            "      CrimeCommission2021ReportClassificationofDefendants  \n",
            "0     Defendant could not be classified or tracked d...    \n",
            "4     New criminal offense punishable by incarcerati...    \n",
            "11    Defendant Detained Entire Pre-Trial Period_Und...    \n",
            "12    New criminal offense punishable by incarcerati...    \n",
            "15    New criminal offense punishable by incarcerati...    \n",
            "...                                                 ...    \n",
            "2163  New criminal offense punishable by incarcerati...    \n",
            "2168  Contact Event was solely related to a preexist...    \n",
            "2170  New criminal offense punishable by incarcerati...    \n",
            "2173  New criminal offense punishable by incarcerati...    \n",
            "2174  New criminal offense punishable by incarcerati...    \n",
            "\n",
            "[652 rows x 709 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type = df['SentenceTypeAllChargesAtConvictionInContactEvent']\n",
        "\n",
        "print(type.head())\n",
        "print(type.unique())\n",
        "print(type.value_counts())"
      ],
      "metadata": {
        "id": "1I-da04PLIAS",
        "outputId": "166b1dd2-42a3-4dc4-bcf4-e97da1b7ee57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1I-da04PLIAS",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    9\n",
            "1    0\n",
            "2    1\n",
            "3    1\n",
            "4    4\n",
            "Name: SentenceTypeAllChargesAtConvictionInContactEvent, dtype: int64\n",
            "[9 0 1 4 2]\n",
            "1    645\n",
            "4    632\n",
            "0    548\n",
            "2    333\n",
            "9     20\n",
            "Name: SentenceTypeAllChargesAtConvictionInContactEvent, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c11bcd96-2834-41a4-80fe-d354b4277fd9",
      "metadata": {
        "id": "c11bcd96-2834-41a4-80fe-d354b4277fd9"
      },
      "source": [
        "**Q3.** This question provides some practice doing exploratory data analysis and visualization.\n",
        "\n",
        "The \"relevant\" variables for this question are:\n",
        "  - `level` - Level of institution (4-year, 2-year)\n",
        "  - `aid_value` - The average amount of student aid going to undergraduate recipients\n",
        "  - `control` - Public, Private not-for-profit, Private for-profit\n",
        "  - `grad_100_value` - percentage of first-time, full-time, degree-seeking undergraduates who complete a degree or certificate program within 100 percent of expected time (bachelor's-seeking group at 4-year institutions)\n",
        "\n",
        "1. Load the `./data/college_completion.csv` data with Pandas.\n",
        "2. What are are the dimensions of the data? How many observations are there? What are the variables included? Use `.head()` to examine the first few rows of data.\n",
        "3. Cross tabulate `control` and `level`. Describe the patterns you see.\n",
        "4. For `grad_100_value`, create a histogram, kernel density plot, boxplot, and statistical description.\n",
        "5. For `grad_100_value`, create a grouped kernel density plot by `control` and by `level`. Describe what you see. Use `groupby` and `.describe` to make grouped calculations of statistical descriptions of `grad_100_value` by `level` and `control`. Which institutions appear to have the best graduation rates?\n",
        "6. Create a new variable, `df['levelXcontrol']=df['level']+', '+df['control']` that interacts level and control. Make a grouped kernel density plot. Which institutions appear to have the best graduation rates?\n",
        "7. Make a kernel density plot of `aid_value`. Notice that your graph is \"bi-modal\", having two little peaks that represent locally most common values. Now group your graph by `level` and `control`. What explains the bi-modal nature of the graph? Use `groupby` and `.describe` to make grouped calculations of statistical descriptions of `aid_value` by `level` and `control`.\n",
        "8. Make a scatterplot of `grad_100_value` by `aid_value`. Describe what you see. Now make the same plot, grouping by `level` and then `control`. Describe what you see. For which kinds of institutions does aid seem to increase graduation rates?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98d34a3b-c21d-4dc9-a8d2-fb7686804ceb",
      "metadata": {
        "id": "98d34a3b-c21d-4dc9-a8d2-fb7686804ceb"
      },
      "source": [
        "**Q4.** This question uses the Airbnb data to practice making visualizations.\n",
        "\n",
        "  1. Load the `./data/airbnb_hw.csv` data with Pandas. You should have cleaned the `Price` variable in question 2, and you'll need it later for this question.\n",
        "  2. What are are the dimensions of the data? How many observations are there? What are the variables included? Use `.head()` to examine the first few rows of data.\n",
        "  3. Cross tabulate `Room Type` and `Property Type`. What patterns do you see in what kinds of rentals are available? For which kinds of properties are private rooms more common than renting the entire property?\n",
        "  4. For `Price`, make a histogram, kernel density, box plot, and a statistical description of the variable. Are the data badly scaled? Are there many outliers? Use `log` to transform price into a new variable, `price_log`, and take these steps again.\n",
        "  5. Make a scatterplot of `price_log` and `Beds`. Describe what you see. Use `.groupby()` to compute a desciption of `Price` conditional on/grouped by the number of beds. Describe any patterns you see in the average price and standard deviation in prices.\n",
        "  6. Make a scatterplot of `price_log` and `Beds`, but color the graph by `Room Type` and `Property Type`. What patterns do you see? Compute a description of `Price` conditional on `Room Type` and `Property Type`. Which Room Type and Property Type have the highest prices on average? Which have the highest standard deviation? Does the mean or median appear to be a more reliable estimate of central tendency, and explain why?\n",
        "  7. We've looked a bit at this `price_log` and `Beds` scatterplot. Use seaborn to make a `jointplot` with `kind=hex`. Where are the data actually distributed? How does it affect the way you think about the plots in 5 and 6?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
      "metadata": {
        "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
      },
      "source": [
        "**Q5.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
        "\n",
        "1. How did the most recent US Census gather data on race?\n",
        "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
        "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
        "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
        "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
        "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f38f2fd-6381-481d-bba9-017f3d363426",
      "metadata": {
        "id": "2f38f2fd-6381-481d-bba9-017f3d363426"
      },
      "source": [
        "**Q6.** Open the `./data/CBO_data.pdf` file. This contains tax data for 2019, explaining where the money comes from that the U.S. Federal Government Spends in terms of taxation on individuals/families and payroll taxes (the amount that your employer pays in taxes on your wages).\n",
        "\n",
        "For some context, the Federal government ultimately spent about $4.4 trillion in 2019, which was 21% of GDP (the total monetary value of all goods and services produced within the United States). Individual Income Taxes is the amount individuals pay on their wages to the Federal government, Corporate Income Taxes is the taxes individuals pay on capital gains from investment when they sell stock or other financial instruments, Payroll Taxes is the tax your employer pays on your wages, Excises and Customs Duties are taxes on goods or services like sin taxes on cigarettes or alcohol, and Estate and Gift Taxes are taxes paid on transfers of wealth to other people.\n",
        "\n",
        "1. Get the Millions of Families and Billions of Dollars data into a .csv file and load it with Pandas.\n",
        "2. Create a bar plot of individual income taxes by income decile. Explain what the graph shows. Why are some values negative?\n",
        "3. Create a bar plot of Total Federal Taxes by income decile. Which deciles are paying net positive amounts, and which are paying net negative amounts?\n",
        "4. Create a stacked bar plot for which Total Federal Taxes is grouped by Individual Income Taxes, Payroll Taxes, Excises and Customs Duties, and Estate and Gift Taxes. How does the share of taxes paid vary across the adjusted income deciles? (Hint: Are these the kind of data you want to melt?)\n",
        "5. Below the Total line for Millions of Families and Billions of Dollars, there are data for the richest of the richest families. Plot this alongside the bars for the deciles above the Total line. Describe your results.\n",
        "6. Get the Percent Distribution data into a .csv file and load it with Pandas. Create a bar graph of Total Federal Taxes by income decile.\n",
        "7. A tax system is progressive if higher-income and wealthier individuals pay more than lower-income and less wealthy individuals, and it is regressive if the opposite is true. Is the U.S. tax system progressive in terms of amount paid? In terms of the percentage of the overall total?\n",
        "8. Do the rich pay enough in taxes? Defend your answer."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}